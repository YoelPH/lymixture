{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the full EM algorithm\n",
    "\n",
    "This represents a simple test with synthetic data to see if the EM-algorithm with the lymphatic progression model works as intended.\n",
    "\n",
    "As always, we start with some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "rng = np.random.default_rng(12345)\n",
    "\n",
    "from lymixture import LymphMixture\n",
    "from lymixture.utils import binom_pmf, late_binomial, normalize\n",
    "from lymph.models import Unilateral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic Data\n",
    "\n",
    "The following parameters were used to generate a synthetic dataset of 3000 patients. one third used the `PARAMS_C1`, another third the `PARAMS_C2` and the last third represents a 50/50 mix of the two.\n",
    "\n",
    "```json\n",
    "PARAMS_C1 = {\n",
    "    \"TtoII_spread\": 0.5,\n",
    "    \"TtoIII_spread\": 0.25,\n",
    "    \"TtoIV_spread\": 0.1,\n",
    "    \"IItoIII_spread\": 0.4,\n",
    "    \"IIItoIV_spread\": 0.3,\n",
    "    \"late_p\": 0.5,\n",
    "}\n",
    "PARAMS_C2 = {\n",
    "    \"TtoII_spread\": 0.65,\n",
    "    \"TtoIII_spread\": 0.15,\n",
    "    \"TtoIV_spread\": 0.05,\n",
    "    \"IItoIII_spread\": 0.5,\n",
    "    \"IIItoIV_spread\": 0.4,\n",
    "    \"late_p\": 0.5,\n",
    "}\n",
    "```\n",
    "\n",
    "Below we load the synthetic dataset generated witht these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/mixture.csv\", header=[0, 1, 2])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {\n",
    "    (\"tumor\", \"T\"): [\"II\", \"III\"],\n",
    "    (\"lnl\", \"II\"): [\"III\"],\n",
    "    (\"lnl\", \"III\"): [],\n",
    "}\n",
    "num_components = 2\n",
    "\n",
    "mixture = LymphMixture(\n",
    "    model_cls=Unilateral,\n",
    "    model_kwargs={\"graph_dict\": graph},\n",
    "    num_components=num_components,\n",
    "    universal_p=False,\n",
    ")\n",
    "mixture.load_patient_data(\n",
    "    data,\n",
    "    split_by=(\"tumor\", \"1\", \"subsite\"),\n",
    "    mapping=lambda x: x,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the diagnostic modality to be the same as in the generated dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture.set_modality(\"path\", 1.0, 1.0)\n",
    "# mixture.set_modality(\"diagnose\", 1., 0.81 )\n",
    "mixture.get_all_modalities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix the distribution over diagnosis times for early T-stage (T1 & T2) to be a binomial distribution with a parameters $p=0.3$.\n",
    "\n",
    "The late T-stage's diagnosis time distribution is a binomial one with a free model parameter than needs to be learned as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture.set_distribution(\"early\", binom_pmf(np.arange(11), 10, 0.3))\n",
    "mixture.set_distribution(\"late\", late_binomial)\n",
    "mixture.get_all_distributions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The EM-Algorithm\n",
    "\n",
    "Here, we initialize random model parameters and latent variables/responsibilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lymixture.em import expectation, maximization\n",
    "\n",
    "params = {k: rng.uniform() for k in mixture.get_params()}\n",
    "mixture.set_params(**params)\n",
    "mixture.normalize_mixture_coefs()\n",
    "latent = normalize(rng.uniform(size=mixture.get_resps().shape).T, axis=0).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define some helper functions, as well as a function to check the convergence of the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(params: dict[str, float]) -> np.ndarray:\n",
    "    return np.array([p for p in params.values()])\n",
    "\n",
    "def is_converged(\n",
    "    history: list[dict[str, float]],\n",
    "    rtol: float = 1e-4,\n",
    ") -> bool:\n",
    "    if len(history) < 2:\n",
    "        return False\n",
    "\n",
    "    old, new = to_numpy(history[-2]), to_numpy(history[-1])\n",
    "    return np.allclose(old, new, rtol=rtol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterate the computation of the expectation value of the latent variables (E-step) and the maximization of the (complete) data log-likelihood w.r.t. the model parameters (M-step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "snapshot = {\n",
    "    \"llh\": mixture.incomplete_data_likelihood(),\n",
    "    **mixture.get_params(as_dict=True, as_flat=True),\n",
    "}\n",
    "history = [snapshot]\n",
    "\n",
    "while not is_converged(history, rtol=1e-2):\n",
    "    print(f\"iteration {count:>3d}: {history[-1]['llh']:.3f}\")\n",
    "    count += 1\n",
    "\n",
    "    latent = expectation(mixture, params)\n",
    "    assert np.allclose(latent.sum(axis=1), 1.)\n",
    "    params = maximization(mixture, latent)\n",
    "\n",
    "    snapshot = {\n",
    "        \"llh\": mixture.incomplete_data_likelihood(),\n",
    "        **mixture.get_params(as_dict=True, as_flat=True),\n",
    "    }\n",
    "    history.append(snapshot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Let's have a look at the convergence and the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history)\n",
    "history_df.plot(\n",
    "    y=[\"llh\", \"0_TtoII_spread\", \"1_TtoII_spread\"],\n",
    "    subplots=[(\"llh\",), (\"0_TtoII_spread\", \"1_TtoII_spread\")],\n",
    "    sharex=True,\n",
    "    xlim=(0, None),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture.get_params(as_dict=True, as_flat=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lymixture.em import complete_samples, sample_model_params\n",
    "\n",
    "samples = sample_model_params(mixture, steps=20)\n",
    "indices = np.random.choice(len(samples), 50, replace=False)\n",
    "reduced_set = samples[indices]\n",
    "complete_samples = complete_samples(mixture, reduced_set)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
